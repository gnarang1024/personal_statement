\documentclass[10pt]{article}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\begin{document}
\author{Armon Shariati}
\title{Dynamic Replanning Cues From Scene Parsing and Object Recognition}
\date{}
\maketitle

Some mobile robots encounter more uncertainty in their environments than
others.  Arguably, disaster relief robots operate in some of the most highly
unpredictable environments imaginable. To date, most of the robotic systems
that handle such scenarios are telerobotic. However, teaching people to control
such systems, and relaying sufficient information to the operator to make
intelligent decisions, are challenging problems. In addition, advancements in
sensing technology, advancements in computing hardware, and the falling costs
of both, are responsible for attracting the attention of researchers to develop
autonomous agents to accomplish the task. The DARPA Robotics Challenge serves
as primary evidence for this shift in research trends.

In order to complete any task, the robot must have the intelligence to create a
plan. That plan could be anything from the necessary set of waypoints a robotic
car must reach to reach a destination or the order in which a set of modular
robots must organize themselves. However, most of these plans are generated in
static environments which often times make the assumption that obstacles are
rigid. Consider a situation where a building may be collapsing and the robot is
trying find humans in the wreckage. If the robot suddenly finds itself
surrounded by rubble because of falling debris, then not only is its former
plan invalid but conventional anytime planning algorithms would not be able to
provide a solution. Dynamic replanning algorithms seek to address similar
problems by quickly computing an optimal solution. However, situations such as
the one mentioned are complex planning problems. Furthermore, the agent may not
have enough time to deliberate a solution using dynamic replanning alone.
Recently, much work is being done in order to find ways of finding solutions to
complex planning problems where environments are dynamic and time is a factor
\cite{likhachev}.

While working at the GRASP Lab at the University of Pennsylvania as a summer
REU student, one of my close friends on the program was working with a graduate
student on this class of problem. Specifically, they were investigating the
possibility of moving an obstacle in order to generate a new plan, after
removing the assumption of static obstacles from their model. While they were
more interested in the planning aspect to the problem, I was wondering how one
could use more sophisticated machine perception techniques in order to detect
whether or not an obstacle can be moved.

Human beings have an incredible ability of being able to see objects that they
have never seen before and instantly know how they could potentially interact
with them. This skill is exactly what allows humans to adapt to and manipulate
their environment. Computer vision has come a long way, but is still far from
solving this problem. However, recent advances in sensing technology such as
RGBD sensors like the Microsoft Kinect, have allowed researchers to make bounds
of progress when addressing the problem in an indoor setting. Among these
techniques include the use of scene parsing as a means for better object
recognition. By segmenting the different components of a setting from an image,
object recognition software can make better decisions when trying to classify
potential candidates. New state of the art methods such as those seen in
\cite{gupta}, have seen much success understanding indoor scenes and using
scene categories for effective segmentation.

I would like to investigate the use of these computer vision techniques as
planning cues for a robot in a dynamic environment. My research would require
funding for the platform construction. I propose constructing a simple four
wheeled robot with a simple manipulater, that can recognize mutable obstacles,
performs any necessary manipulation tasks to modify its environment, and then
efficiently reconstruct a plan. I would like to immerse myself within
perception and planning literature equally in order to construct the best
possible solution, which draws upon the state of the art in both subjects. The
success of my project would likely contribute more to the study of planning
algorithms. If engineers in this field find that there are effective vision
tools that can provide more detailed information about their precarious
enviroments, then perhaps more sophisticated planning algorithms can be
developed that would be both fast, optimal, and applicable to dynamic
environments with complex planning problems.

Broader implications of my research include endangering fewer lives in the
event of disasters. The use of such technology would mean that fewer responders
would be needed to enter hazardous environments such as burning buildings,
accident sites, and natural disaster zones. After events such as Fukushima and
9-11, many lives were lost after the disaster as a result of people being
exposed to hazardous material, even though tasks such as sifting through rubble
could be more efficiently performed by a machine. Ultimately, as the human
population continues to grow exponentially and urban centers growing more
crowded, accidents are inevitable. It is our responsibility as researchers to
utilize the advancements in manufacturing and technology to engineer relevant
solutions that find their way into the lives of people as quickly as possible.


\begin{thebibliography}{9}

\bibitem{likhachev}
  Maxim Likhachev, Dave Ferguson, Geoff Gordon, Anthony Stentz, and Sebastian Thrun,
  \emph{Anytime Dynamic A*: An Anytime, Replanning Algorithm}.
  ICAPS,
  2005.

\bibitem{gupta}
  Saurabh Gupta, Pablo Arbelaez, Jitendra Malik,
  \emph{Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images}.
  Computer Vision and Pattern Recognition,
  2013.

\end{thebibliography}




\end{document}
