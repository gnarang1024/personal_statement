\documentclass[10pt]{article}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\begin{document}
\author{Armon Shariati}
\title{Dynamic Replanning Cues From Scene Parsing and Object Recognition}
\date{}
\maketitle

Some mobile robots encounter more uncertainty in their environments than
others.  Arguably, disaster relief robots operate in some of the most highly
unpredictable environments imaginable. Most of the robotic systems that handle
such scenarios are currently telerobotic. However, rising costs of training
telerobotic operators, in tandem with recent advancements in computing,
manufacturing, and sensing technology, have greatly improved the prospects of
developing autonomous agents as viable solutions. The DARPA Robotics Challenge
serves as primary evidence for this shift in research trends.

In order to complete any task, the robot must have the intelligence to create a
plan. These plans can be anything from the order in which a robotic arm must
stack blocks, the configuration in which a set of modular robots must arrange
themselves, or the necessary set of waypoints a robotic car must traverse in
order to safely arrive at its destination. However, many of these planners
operate within static environments, and often times make the assumption that
obstacles are rigid. Consider a situation where a building is collapsing and
the robot is trying find humans in the wreckage. If the robot suddenly finds
itself surrounded by rubble because of falling debris, then not only is its
former plan invalid, but conventional anytime planning algorithms would not be
able to provide a solution. Dynamic replanning algorithms seek to address
similar problems; they are able to quickly compute an optimal solution.
Situations such as the one mentioned are also complex planning problems.
Furthermore, in such cases the agent may not have enough time to deliberate a
solution using dynamic replanning alone. A lot of attention has recently been
given to finding solutions to complex planning problems where environments are
dynamic and time is a constraint \cite{likhachev}.

While working at the GRASP Laboratory at the University of Pennsylvania as a
summer REU student, one of my close friends in the program was working with a
graduate student on this class of problem. Specifically, they were
investigating the possibility of moving an obstacle in order to generate a new
plan after removing the assumption of static obstacles from their model.
Whereas their research interests lay more in the planning aspect to the
problem, I was curious as to how one could use more sophisticated perception
tools in order to detect potentially movable objects.

Human beings have the remarkable ability of being able to see objects that they
have never encountered before and instantly know how they could potentially
interact with them. This skill is exactly what allows humans to adapt to and
manipulate their environment so effectively. Computer vision has come a long
way, but is still far from solving this problem. However, affordable and modern
sensing technology such as RGBD sensors like the Microsoft Kinect, have allowed
researchers to make significant progress addressing the problem in an indoor
setting.  Identifying an object encompasses three other major problems
including segmentation, detection, and class recognition. Scene parsing is a
newer technique, which aims to solve all three problems at once with a single
process. By first segmenting out different structural elements of the image,
scene parsing methods attempt to make better decisions when trying to detect
and classify objects. New state of the art methods such as those seen in
\cite{gupta}, have experienced much success in attempting to understand indoor
scenes by using scene categories for effective segmentation. I would like to
investigate the use of these computer vision techniques as planning cues for a
robot in a dynamic environment.

I propose the construction of a four wheeled robot with a simple manipulator.
The robot would be equipped with an initial map of its environment, a means for
localization, and a goal destination. Using the information provided, the robot
would then construct a plan to safely and efficiently reach the objective.
However, while the robot is executing its plan, the environment would
dynamically change and possibly trap the robot.  In such a circumstance, the
robot should be able to differentiate between fixed and dynamic objects, move
any identified impeding dynamic obstacles, and finally reconstruct a plan to
the destination. A successful implementation would likely contribute most to
the field of planning algorithms. With a robust means of detecting dynamic
elements in an environment, perhaps more sophisticated planning algorithms can
be developed that consider a greater degree of real world uncertainty and
address more complex problems.

Broader implications of my research include endangering fewer lives in the
event of disasters. The use of such technology would mean that fewer responders
would be needed to enter hazardous environments such as burning buildings,
accident sites, and natural disaster zones. During events such as Fukushima and
9-11, the lives of many volunteers and first responders were lost in the
immediate aftermath of the disaster as a result of being exposed to hazardous
material while trying to clear wreckage in order to find survivors. Sifting
through rubble and other hazardous material is a dangerous task, and can be
done more efficiently and safely by a machine. Ultimately, as the human
population continues to grow exponentially and urban centers become more dense,
accidents are inevitable. It is our responsibility as researchers to utilize
all available advancements in technology to engineer relevant solutions that
find their way into the hands of people as quickly as possible.


\begin{thebibliography}{9}

\bibitem{likhachev}
  Maxim Likhachev, Dave Ferguson, Geoff Gordon, Anthony Stentz, and Sebastian Thrun,
  \emph{Anytime Dynamic A*: An Anytime, Replanning Algorithm}.
  ICAPS,
  2005.

\bibitem{gupta}
  Saurabh Gupta, Pablo Arbelaez, Jitendra Malik,
  \emph{Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images}.
  Computer Vision and Pattern Recognition,
  2013.

\end{thebibliography}




\end{document}
