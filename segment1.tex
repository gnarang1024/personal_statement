Professor John Spletzer, extended me the opportunity to work in his laboratory
as an REU student in the summer of 2013. I worked under a stern, yet
compassionate graduate student gaining research skill and discipline over the
course of several months extending through the Fall semester. In the spring, I
was a co-author on a paper and presented our findings at the conference.

In the summer of 2014 I participated in the NSF sponsored, GRASP REU program at
the University of Pennsylvania. I worked with Professor CJ Taylor developing a
general platform for creating virtual reality applications that integrate
cutting edge haptic devices with state of the art gaming displays. At the end
of the program, I had finished a demo and even won the award for best REU
research paper. In the fall, I had an abstract accepted by the Northeast
Robotics Colloquium, where I presented my work in a poster session.

My senior year, I inherited a graduate-level research project, the Lehigh
Mapping Tricycle (LMT). The LMT project is motivated by the lack of means to
construct large-scale feature maps in outdoor urban environments required for
our Smart Wheelchair System.  Data from the LMT's proprioceptive sensors
including a GPS module, an IMU, and encoder, are fused together to generate an
estimate of its position in 3D space. With 3D odometry in place, vertical LIDAR
scans taken from either side of the vehicle are aggregated in order to create a
3D point cloud, from which pole-like features are extracted for mapping. Using
variations of SLAM, the locations of poles are optimized over the path the
robot has taken in order to generate a 2D map.  After inheriting the majority
of the hardware, I wrote the software for robust pose estimation, pole
segmentation, and map generation. The work I have completed as of December 2014
has even been incorporated as a section in our latest journal submission. 
